<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>High Performance Computing at NYU</title>

<script src="site_libs/header-attrs-2.24/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="shortcut icon" href="favicon.ico" />
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore"><strong>High Performance Computing at
NYU</strong></h1>

</div>


<div id="motivation" class="section level3">
<h3><strong>Motivation</strong></h3>
<p>Experimental research projects often require substantial computing
resources. Fortunately, NYU provides access to a high performance
computing (HPC) cluster for affiliated researchers. Unfortunately, the
HPC cluster is surprisingly challenging to use. After years of
struggling with it, I finally feel like I know what’s going on. In the
hopes that I could save you some time, I’ve compiled the information I
wish I were told years ago.</p>
<p>Note: There are many other resources that explain how to use HPC (
the official docs are <a
href="https://sites.google.com/nyu.edu/nyu-hpc/accessing-hpc?authuser=0">here</a>).</p>
</div>
<div id="initial-set-up" class="section level3">
<h3><strong>Initial Set Up</strong></h3>
<p>There are several steps to getting an account and accessing the
cluster.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Requesting access</strong>. The HPC cluster is a powerful
resource. As a result, NYU restricts who can use it. If you’re not a NYU
faculty member, you’ll need an NYU faculty sponsor and you’ll have to
renew access every year. The steps are described <a
href="https://www.nyu.edu/life/information-technology/research-computing-services/high-performance-computing/high-performance-computing-nyu-it/hpc-accounts-and-eligibility.html">here</a>.</p></li>
<li><p><strong>Setting up the VPN (Optional)</strong>. Accessing the HPC
cluster requires either working from NYU Wi-Fi or connecting via a VPN.
The steps to set up a VPN are linked to under “Top Support Articles” <a
href="https://www.nyu.edu/life/information-technology/infrastructure/network-services/vpn.html">here</a>.</p></li>
<li><p><strong>Authenticating</strong>. There are several ways you can
access the HPC cluster from your personal computer. I strongly recommend
using VS Code. The steps to authenticate via VS Code are described <a
href="https://sites.google.com/nyu.edu/nyu-hpc/training-support/general-hpc-topics/vs-code">here</a>.</p></li>
</ol>
</div>
<div id="overview" class="section level3">
<h3><strong>Overview</strong></h3>
<center>
<img src="images/hpc.png" width="800">
</center>
<p>Now that you’re able to access it, let’s understand how the HPC
cluster works. You will access the cluster from a personal computer (on
NYU Wi-Fi or a VPN). Once you authenticate, you’ll be placed onto a
login node. A login node has limited resources and, as I’ve found out
from angry emails, should <strong>not</strong> be used for running jobs.
In order to run a job, you’ll request access to a compute node. A
compute node has lots of resources and should be used for running jobs.
(In your request, you’ll specify how long you want the compute node, how
many CPUs/GPUs you’ll need, etc.) Once you’re on a compute node, you
will use the following three steps to run code.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Execute your singularity</strong>. A singularity keeps
your packages in a nice and tidy container.</p></li>
<li><p><strong>Activate your conda environment</strong>. Your conda
environment manages the packages you’ll use.</p></li>
<li><p><strong>Run your code</strong>. Yay!</p></li>
</ol>
<p>However, running these steps will require setting up a singularity
and conda environment (the instructions to do so are in the last
section).</p>
<p>HPC allocates two folders for every user. If your NetID is
<code>abc123</code> then your home folder is <code>home/abc123</code>
and your scratch folder is <code>scratch/abc123</code>. As far as I can
tell, the home folder is basically useless: it has limited space and, as
I’ve found out from even more angry emails, should <strong>not</strong>
be used for storing code. The scratch folder, appropriately called has
lots of space and should be used for storing code.</p>
</div>
<div id="running-code" class="section level3">
<h3><strong>Running Code</strong></h3>
<p>There are two ways to run code on the HPC cluster: interactively or
in a slurm job. Both methods begin in a login node. But, before you try
either of the methods described in this section, you
<strong>must</strong> complete the instructions for one time set up in
the last section.</p>
<div id="interactively" class="section level4">
<h4><strong>Interactively</strong></h4>
<p>You can run code interactively by requesting a compute node,
executing your singularity, and then activating your conda environment.
You can request an interactive compute node with the following:</p>
<p><code>srun --nodes=1 --tasks-per-node=1 --cpus-per-task=4 --gres=gpu:1 --mem=32GB --time=0:20:00 --pty /bin/bash</code></p>
<p>Here, we requested one node with 32GB of memory, four CPUs, and one
GPU for 20 minutes. Once you’ve been assigned a compute node (this may
take a little while), you can execute your singularity with the
following</p>
<p><code>singularity exec --nv --overlay $SCRATCH/overlay-25GB-500K.ext3:rw /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash</code></p>
<p>Note that the <code>nv</code> flag tells the singularity to expect a
GPU (this is fine in general since it will only throw a warning if you
don’t have a GPU). Once you’re in the singularity, you can load your
environment with <code>conda activate envname</code>. Now you should be
all set to run your code!</p>
</div>
<div id="sbatch-job" class="section level4">
<h4><strong>Sbatch Job</strong></h4>
<p>For jobs that take awhile to run, we can submit them using slurm. An
example slurm file appears below.</p>
<pre><code>#!/bin/bash

#SBATCH --job-name=jobname
#SBATCH --open-mode=append
#SBATCH --output=./%x_%j.out
#SBATCH --error=./%x_%j.err
#SBATCH --export=ALL
#SBATCH --time=1:00:00
#SBATCH --gres=gpu:1
#SBATCH --mem=32G
#SBATCH --mail-type=END
#SBATCH --mail-user=abc123@nyu.edu
#SBATCH -c 8

singularity exec --nv --overlay $SCRATCH/overlay-25GB-500K.ext3:rw /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash -c &quot;
source /ext3/env.sh
conda activate envname
python code.py
&quot;</code></pre>
<p>The flags provide a convenient way of requesting special behavior in
your job. After the flags, we execute a singularity load conda, activate
the conda environment <code>envname</code>, and then run the code in
<code>code.py</code>. If the sbatch file is called
<code>run.slurm</code>, you can submit it by running
<code>sbatch run.slurm</code> from the command line in a login node. You
can check the status of the job by running
<code>squeue --user abc123</code>.</p>
</div>
</div>
<div id="one-time-set-up-for-singularity-and-conda"
class="section level3">
<h3><strong>One Time Set Up for Singularity and Conda</strong></h3>
<p>I struggled to find good instructions for setting up the singularity
and conda environments for a long time. Fortunately, <a
href="https://www.lucasrosenblatt.com/">Lucas Rosenblatt</a> kindly
shared the following instructions which have worked very well for
me.</p>
<p>After authenticating to the HPC cluster and connecting to a login
node, you should navigate to your scratch folder
<code>scratch/abc123</code> (of course, replace <code>abc123</code> with
your own NetID).</p>
<div id="creating-an-overlay" class="section level4">
<h4><strong>Creating an Overlay</strong></h4>
<p>We’ll first copy an overlay (a writable file system for your
singularity) to your scratch folder. You can accomplish this by running
the following on the command line:</p>
<p><code>cp /scratch/work/public/overlay-fs-ext3/overlay-25GB-500K.ext3.gz .</code></p>
<p>Here, we chose one of the overlays with a decent amount of memory.
Now you’ll unzip your overlay with the following:</p>
<p><code>gunzip -vvv ./overlay-25GB-500K.ext3.gz</code></p>
<p>Don’t be surprised if the unzipping process takes a little while to
run (after all, we are on a login node).</p>
</div>
<div id="setting-up-conda" class="section level4">
<h4><strong>Setting Up Conda</strong></h4>
<p>Before we execute the singularity, let’s transition to a compute
node. We can request a compute node with the following:</p>
<p><code>srun --nodes=1 --tasks-per-node=1 --cpus-per-task=1 --mem=32GB --time=0:20:00 --pty /bin/bash</code></p>
<p>Here, we’ve requested one compute node with 32GB of memory for 20
minutes. We’ll start the singularity with the following:</p>
<p><code>singularity exec --overlay $SCRATCH/overlay-25GB-500K.ext3:rw /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash</code></p>
<p>Once we’re in the singularity, we’ll navigate to a new folder with
<code>cd /ext3/</code> and install conda here. We can download miniconda
with the following:</p>
<p><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</code></p>
<p>Once it’s downloaded, we will install conda by running:</p>
<p><code>bash ./Miniconda3-latest-Linux-x86_64.sh</code></p>
<p>The installation process is a little delicate. First, you will be
prompted to agree to some terms. Next, you will be asked for the
location of where you want conda installed. It’s <em>very</em> important
that you specify <code>miniconda3</code>. Otherwise, the file system
gets messed up and it’s difficult to run jobs later on. Finally, you’ll
be prompted to agree to something else.</p>
</div>
<div id="creating-a-conda-environment" class="section level4">
<h4><strong>Creating a Conda Environment</strong></h4>
<p>For the installation to take effect, you’ll need to exit the
singularity (type <code>exit</code>) and re-enter it (use the same code
snippet from before).</p>
<p>Now we’ll make sure conda works correctly by running
<code>conda activate</code>. Your command line prompt should now have
<code>(base)</code> before it. You can now create a new conda
environment with the following:</p>
<p><code>conda create -n "envname" python=3.10</code></p>
<p>Check that the environment works correctly by running
<code>conda activate envname</code>. Finally, you can install all your
packages by running <code>pip install packagename</code>.</p>
</div>
<div id="bash-script-for-activating-conda" class="section level4">
<h4><strong>Bash Script for Activating Conda</strong></h4>
<p>When you run code inside a slurm job, you’ll need to activate the
conda environment <em>before</em> calling <code>conda activate</code> (I
have no idea why). Fortunately, we can handle this with a bash script.
Make sure you’re in a singularity on a compute node and in the
<code>/ext3/</code> folder. From here, run <code>bash</code> and then
the following to download the bash script:</p>
<p><code>wget https://gist.githubusercontent.com/uralik/2760833e55be112eda8352f831626419/raw/dd800529551cf0f698d3aca3bb6544076b5ece98/env.sh -O /ext3/env.sh</code></p>
<p>For sanity, double check that you see a folder called
<code>miniconda3</code> in <code>/ext3/</code> as well. If not, the
source will not load properly. (You can try deleting everything in
<code>/ext3/</code> and repeating the instructions in “Setting Up Conda”
to fix this.)</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
